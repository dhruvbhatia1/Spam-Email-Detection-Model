{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b0089b-09bd-4e35-9f81-d4715e636c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346af7be-df31-4542-b8f9-b764b77d07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bayes/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62f5c74d-ba14-4323-81a2-a6ad032e9f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ham',\n",
       "        'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Ok lar... Joking wif u oni...', nan, nan, nan],\n",
       "       ['spam',\n",
       "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "        nan, nan, nan],\n",
       "       ...,\n",
       "       ['ham',\n",
       "        'Pity, * was in mood for that. So...any other suggestions?', nan,\n",
       "        nan, nan],\n",
       "       ['ham',\n",
       "        \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Rofl. Its true to its name', nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447bd87f-67ab-425e-b73c-10feb814942a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be4ffe7a-2d23-4c7c-b026-0a5aca7bbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1]\n",
    "y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ab181e-38ce-4e22-8308-22c58719dbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572,), (5572,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18771096-d1d1-4a37-917c-cf6415b029f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da53a151-cced-44bb-b809-dceb64608658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStem(review):\n",
    "    review = review.lower()\n",
    "    tokens = tokenizer.tokenize(review) #breaking into small words\n",
    "    removed_stopwords = [w for w in tokens if w not in sw]\n",
    "    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n",
    "    clean_review = ' '.join(stemmed_words)\n",
    "    return clean_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e14ee65-c168-431e-a3eb-e1bdb343d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a clean document\n",
    "def getDoc(document):\n",
    "    d = []\n",
    "    for doc in document:\n",
    "        d.append(getStem(doc))\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c5129cb-4814-4033-8131-5a3c9e7c0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_doc = getDoc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e482c8c3-847c-4ab6-b6ab-8f69788ae460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though',\n",
       " 'freemsg hey darl 3 week word back like fun still tb ok xxx std chg send å 1 50 rcv',\n",
       " 'even brother like speak treat like aid patent',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun',\n",
       " 'winner valu network custom select receivea å 900 prize reward claim call 09061701461 claim code kl341 valid 12 hour',\n",
       " 'mobil 11 month u r entitl updat latest colour mobil camera free call mobil updat co free 08002986030']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_doc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b8ededd-3ddb-4823-a564-19295ae50c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9a4f8d7-667a-451b-afa8-7bf9603b391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my vocab\n",
    "vc = cv.fit_transform(stemmed_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "004fd26f-9aa3-4475-b14b-520c076c56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad9926-0b40-44a8-b2f3-121adb621399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939f01e-0dc4-4d1f-9229-cefbff86775c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02a8619f-c495-49f4-8330-430f2b047074",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2cd825e-347f-452f-a401-06c0103b05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e450265-3c0a-4d17-9d02-44201ac43be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977705274605764"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc0f9022-b7a9-4662-9a7d-82fd072c729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"GEt 100% off on MUj fees. Limited time offer. Call me.\"\"\",\n",
    "    \"\"\"Let's go to the mall, today.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c270663-dbd0-44ad-8c3d-54a12ad37e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(messages):\n",
    "    d = getDoc(messages)\n",
    "    #don't do fit_transform\n",
    "    return cv.transform(d)\n",
    "messages = prepare(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3b6baf9-1056-4afd-907d-751fa409616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(messages)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d341bf-46e6-4f9c-9f49-3adc1bb8fdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
